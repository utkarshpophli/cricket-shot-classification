
# Introduction

In the realm of computer vision, object classification is a vital task, allowing systems to discern and categorize objects within images or videos. Utilizing deep learning architectures has significantly advanced object classification accuracy and efficiency. This document explores various deep learning models, including VGGNet, ResNet, MobileNet, EfficientNet, and DenseNet, for the classification of cricket shots. These models employ convolutional neural networks (CNNs) to extract features and classify images, providing valuable insights into the actions performed in cricket shots.

![intro](https://i.ibb.co/FV9KD4P/results-7-1.png)
## Libraries Used

To implement the classification task, we rely on popular deep learning libraries such as TensorFlow and Keras. These libraries offer a rich set of tools and pre-trained models, streamlining the development and deployment of classification systems.
## Use Cases

The classification task focuses on identifying distinct cricket shots, including the pull shot, sweep, drive, and leg glance-flick. Each of these shots exhibits unique characteristics, making them distinguishable through image classification techniques.

![use](https://i.ibb.co/RBTQMyw/28415download5.png)
## Results

Through experimentation with various deep learning models—VGGNet, ResNet, MobileNet, EfficientNet, and DenseNet—we evaluate their performance in accurately classifying cricket shots. The results provide insights into the effectiveness of each model for classifying different cricket actions, facilitating informed decisions for application in cricket analysis and training scenarios.

![intro](https://i.ibb.co/885KS71/results-17-0.png)
